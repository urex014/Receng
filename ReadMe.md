# AI-Powered Visual Search & Recommendation Engine

A full-stack e-commerce microservice architecture that enables "Snap & Shop" reverse image search, automated AI product tagging, and real-time "Visually Similar" recommendations. 

Instead of relying on manual text tags, this platform uses a Deep Learning vision model to convert product images into mathematical arrays (feature vectors), storing them in a specialized PostgreSQL vector database for instantaneous similarity matching.



## üöÄ Key Features

* **Reverse Image Search ("Snap & Shop"):** Users can upload a photo of any clothing item, and the engine will mathematically calculate and return the closest matching inventory items in milliseconds.
* **Automated Product Tagging:** Admins upload a single photo, and the AI automatically extracts visual features and generates human-readable tags (via ImageNet cross-referencing).
* **Dynamic "Visually Similar" Carousels:** Product pages automatically display recommendations based on Cosine Distance `<=>` mathematical proximity, requiring zero manual curation.
* **Microservice Architecture:** Fully decoupled frontend, backend orchestrator, and AI processing layers.

## üõ† Tech Stack

* **Frontend:** Next.js (React, TypeScript, Tailwind CSS)
* **Orchestrator API:** Node.js, Express, Prisma ORM, Multer
* **AI Microservice:** Python, FastAPI, ONNX Runtime, OpenCV, NumPy
* **Database:** PostgreSQL with the `pgvector` extension
* **Machine Learning Model:** ResNet50 (Lightweight ONNX format)

---

## ‚öôÔ∏è Local Setup & Installation

Because this is a multi-service architecture, you will need to run three separate servers. Ensure you have **Node.js**, **Python 3**, and **PostgreSQL** installed on your machine.

### 1. Database Setup (PostgreSQL + pgvector)
Ensure PostgreSQL is running and the `pgvector` extension is installed on your OS.

```bash
# Log into Postgres and create the database
sudo -u postgres createdb receng_db

# Enable the vector extension
sudo -u postgres psql -d receng_db -c "CREATE EXTENSION IF NOT EXISTS vector;"
Update your .env file in the Node.js root directory:

Code snippet
DATABASE_URL="postgresql://postgres:YOUR_PASSWORD@localhost:5432/receng_db?schema=public"
Sync the Prisma schema and force the vector size to 1000 dimensions:

Bash
npx prisma db push
sudo -u postgres psql -d receng_db -c 'ALTER TABLE "Product" ALTER COLUMN "featureVector" TYPE vector(1000);'
2. The AI Microservice (Python)
Navigate to your ai-service directory (or wherever your Python code lives) and set up the environment:

Bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install fastapi uvicorn onnxruntime opencv-python pillow numpy python-multipart
Note on ML Models: The resnet50-v1-7.onnx model file is excluded from this repository due to size. You must download it and place it in the Python directory before running.

Bash
# Start the AI Brain (Runs on Port 8000)
python main.py
3. The Backend Orchestrator (Node.js)
Open a new terminal, navigate to your root Node directory, and install dependencies:

Bash
npm install express cors axios multer form-data @prisma/client
npm install prisma --save-dev

# Start the Node Orchestrator (Runs on Port 5000)
node server.js
4. The Frontend (Next.js)
Open a third terminal window, navigate to your Next.js frontend directory:

Bash
npm install
npm run dev
# The frontend will run on http://localhost:3000
üö¶ Usage Workflow
Populate the Database: Navigate to http://localhost:3000/admin/upload. Upload 4-5 different product images to give the database enough vectors to compare.

View Recommendations: Click on a successfully uploaded product. Scroll down to see the "Visually Similar Items" automatically generated by the AI.

Test Visual Search: Navigate to http://localhost:3000/search. Upload a random image from the internet and watch the engine find the closest match from your database.

üîÆ What's Next?
This engine serves as the foundational discovery layer for an upcoming Web3 Peer-to-Peer Marketplace, combining AI-driven visual discovery with trustless smart contract transactions via Solidity.


When you have this successfully pushed to GitHub, are you ready to fire up a new repository to start mapping out the Solidity smart contracts for the Web3 marketplace?